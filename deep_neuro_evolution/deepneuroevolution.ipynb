{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import keras\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import sklearn\n",
    "from itertools import repeat\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepNeuroevolution():\n",
    "    \n",
    "    def __init__(self, env, n_individuals, n_parents, n_features, n_actions, nn_architecture, reward_goal):\n",
    "        self._env = env\n",
    "        self._n_individuals = n_individuals\n",
    "        self._n_parents = n_parents\n",
    "        self._n_features = n_features\n",
    "        self._n_actions = n_actions\n",
    "        self._nn_architecture = nn_architecture\n",
    "        self._reward_goal = reward_goal\n",
    "        self._best_score = -10**10\n",
    "        self._n_generations = 0\n",
    "    \n",
    "    \n",
    "    def find_optimal_network(self):\n",
    "        self._create_first_population()\n",
    "        while not self._is_finished():\n",
    "            self._evaluate_population()\n",
    "            parents = self._create_parents()\n",
    "            self._create_new_population(parents)\n",
    "            self._print_score(parents)\n",
    "            \n",
    "    \n",
    "    def _is_finished(self):\n",
    "        return self._best_score >= self._reward_goal\n",
    "    \n",
    "    \n",
    "    def _evaluate_population(self):\n",
    "        for idx, mlp in enumerate(self._current_population):\n",
    "            score = self._evaluate_network(mlp[0], 10)\n",
    "            self._current_population[idx][1] = score\n",
    "    \n",
    "    \n",
    "    def _evaluate_network(self, mlp, iterations):\n",
    "        score = 0\n",
    "        env = self._env\n",
    "        for _ in range(iterations):\n",
    "            state = env.reset()\n",
    "            done = False\n",
    "            while not done:\n",
    "                action = np.random.choice(self._n_actions, p=mlp.predict([state])[0])\n",
    "                state, reward, done, info = env.step(action)\n",
    "                score += reward\n",
    "        return score / iterations\n",
    "    \n",
    "    \n",
    "    def _create_first_population(self):\n",
    "        self._current_population = []\n",
    "        for _ in range(self._n_individuals):\n",
    "            mlp = MLPRegressor(hidden_layer_sizes = (10,), alpha=10**-10, max_iter=1)\n",
    "            mlp.fit([np.random.randn(self._n_features)], [np.random.randn(self._n_actions)])\n",
    "            mlp.out_activation_ = 'softmax'\n",
    "            self._current_population.append([mlp,0])\n",
    "    \n",
    "    \n",
    "    def _create_parents(self):\n",
    "        parents = sorted(self._current_population, key=lambda x: -x[1])[:self._n_parents]\n",
    "        for idx, mlp in enumerate(parents):\n",
    "            score = self._evaluate_network(mlp[0], 100)\n",
    "            parents[idx][1] = score\n",
    "        parents.sort(key=lambda x:-x[1])\n",
    "        return parents\n",
    "    \n",
    "    \n",
    "    def _create_new_population(self, parents):\n",
    "        new_population = [parents[0]]\n",
    "        for _ in range(self._n_individuals-1):\n",
    "            idx = np.random.randint(len(parents))\n",
    "            weights, biases = self._compute_new_weights(parents[idx][0])\n",
    "            mlp = self._create_new_nn(weights, biases)\n",
    "            new_population.append([mlp, 0])\n",
    "        self._current_population = new_population\n",
    "    \n",
    "    \n",
    "    def _create_new_nn(self, weights, biases):\n",
    "        mlp = MLPRegressor(hidden_layer_sizes = (10,), alpha=10**-10, max_iter=1)\n",
    "        mlp.fit([np.random.randn(self._n_features)], [np.random.randn(self._n_actions)])\n",
    "        mlp.coefs_ = weights\n",
    "        mlp.intercepts_ = biases\n",
    "        mlp.out_activation_ = 'softmax'\n",
    "        return mlp\n",
    "    \n",
    "    \n",
    "    def _compute_new_weights(self, parent):\n",
    "        weights = parent.coefs_\n",
    "        biases = parent.intercepts_\n",
    "        new_weights = []\n",
    "        new_biases = []\n",
    "        for weight in weights:\n",
    "            shape = weight.shape\n",
    "            new_weights.append(weight + 100*np.random.randn(shape[0], shape[1]))\n",
    "        for bias in biases:\n",
    "            new_biases.append(bias + 100*np.random.randn(bias.shape[0]))\n",
    "        return new_weights, new_biases\n",
    "    \n",
    "        \n",
    "    def _print_score(self, parents):\n",
    "        self._best_score = max(self._best_score, parents[0][1])\n",
    "        self._n_generations += 1\n",
    "        print('Results for generation', self._n_generations, '\\n')\n",
    "        print('Overall best score is:', self._best_score)\n",
    "        print('Best scores of the current population:')\n",
    "        for i in parents:\n",
    "            print(i[1])\n",
    "        print('\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v0')\n",
    "# env = gym.make('MountainCar-v0')\n",
    "# env = gym.make('Acrobot-v1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for generation 1 \n",
      "\n",
      "Overall best score is: 47.02\n",
      "Best scores of the current population:\n",
      "47.02\n",
      "40.54\n",
      "27.27\n",
      "25.8\n",
      "21.9\n",
      "\n",
      "\n",
      "Results for generation 2 \n",
      "\n",
      "Overall best score is: 125.96\n",
      "Best scores of the current population:\n",
      "125.96\n",
      "110.91\n",
      "69.15\n",
      "57.98\n",
      "40.75\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "n_features = 4\n",
    "n_actions = 2\n",
    "dne = DeepNeuroevolution(env, 100, 5, n_features, n_actions, (10,), -100)\n",
    "dne.find_optimal_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 452 ms, sys: 290 ms, total: 742 ms\n",
      "Wall time: 20.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def f(x):\n",
    "    return x**10000\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    p = Pool(1)\n",
    "    p.map(f, range(10**4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "20.7\n",
    "11.3\n",
    "10.2\n",
    "10.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 6, 7]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import add\n",
    "\n",
    "list(map(add, [1,2,3], repeat(4)))\n",
    "[5, 6, 7]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
