{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Racetrack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 5.10: Racetrack (programming) Consider driving a race car around a turn like those shown in\n",
    "Figure 5.5. You want to go as fast as possible, but not so fast as to run off the track. In our simplified\n",
    "racetrack, the car is at one of a discrete set of grid positions, the cells in the diagram. The velocity is\n",
    "also discrete, a number of grid cells moved horizontally and vertically per time step. The actions are\n",
    "increments to the velocity components. Each may be changed by +1, −1, or 0 in each step, for a total\n",
    "of nine (3 × 3) actions. Both velocity components are restricted to be nonnegative and less than 5,\n",
    "and they cannot both be zero except at the starting line. Each episode begins in one of the randomly\n",
    "selected start states with both velocity components zero and ends when the car crosses the finish line.\n",
    "The rewards are −1 for each step until the car crosses the finish line. If the car hits the track boundary,\n",
    "it is moved back to a random position on the starting line, both velocity components are reduced to\n",
    "zero, and the episode continues. Before updating the car’s location at each time step, check to see if\n",
    "the projected path of the car intersects the track boundary. If it intersects the finish line, the episode\n",
    "ends; if it intersects anywhere else, the car is considered to have hit the track boundary and is sent\n",
    "back to the starting line. To make the task more challenging, with probability 0.1 at each time step\n",
    "the velocity increments are both zero, independently of the intended increments. Apply a Monte Carlo control method to this task to compute the optimal policy from each starting state. Exhibit several\n",
    "trajectories following the optimal policy (but turn the noise off for these trajectories)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simplify the problem we consider a smooth racetrack, i.e. a rectangle with the lower right quarter missing\n",
    "The rectangle is 10 x 20 (so there are 5 starting positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enviroment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Racetrack():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._size = (20,40)\n",
    "        self.reset()\n",
    "        \n",
    "    def step(self, user_action):\n",
    "        action = self._preprocess_action(user_action)\n",
    "        self._update_velocity(action)\n",
    "        self._update_position()\n",
    "        reward = -1\n",
    "        return self._convert_position(), reward, self._done\n",
    "    \n",
    "    def reset(self):\n",
    "        self._velocity = [0,0]\n",
    "        self._done = False\n",
    "        self._position = [np.random.randint(self._size[0] // 2), 0]\n",
    "        return self._convert_position()\n",
    "    \n",
    "    def _update_position(self):\n",
    "        # simple checking, not totally correct\n",
    "        self._position[0] += self._velocity[0]\n",
    "        self._position[1] += self._velocity[1]\n",
    "        if self._check_for_finish():\n",
    "            self._done = True\n",
    "        elif self._check_for_boundary_hit():\n",
    "            self.reset()\n",
    "        return\n",
    "        \n",
    "    def _check_for_finish(self):\n",
    "        return self._position[0] >= self._size[0] and self._position[1] >= self._size[1] / 2\n",
    "    \n",
    "    def _check_for_boundary_hit(self):\n",
    "        hit_boundary = False\n",
    "        if self._position[0] >= self._size[0] // 2 and self._position[1] <= self._size[1] // 2:\n",
    "            hit_boundary = True\n",
    "        elif self._position[0] >= self._size[0] or self._position[1] >= self._size[1]:\n",
    "            hit_boundary = True\n",
    "        return hit_boundary\n",
    "        \n",
    "    def _update_velocity(self, action):\n",
    "        tmp1 = self._velocity[0] + action[0]\n",
    "        tmp2 = self._velocity[1] + action[1]\n",
    "        self._velocity[0] = min(max(0, tmp1),5)\n",
    "        self._velocity[1] = min(max(0, tmp2),5)\n",
    "    \n",
    "    def _preprocess_action(self, user_action):\n",
    "        action = self._convert_action(user_action)\n",
    "        action = self._disturb_action(action)\n",
    "        return action\n",
    "    \n",
    "    def _disturb_action(self, action):\n",
    "        if np.random.rand() < 0.0:\n",
    "            action = [0,0]\n",
    "        return action\n",
    "    \n",
    "    def _convert_position(self):\n",
    "        return self._position[1] * self._size[0] + self._position[0]\n",
    "    \n",
    "    def _convert_action(self, action):\n",
    "        return [(action % 3)-1, (action // 3)-1]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_history_mc_episode(q, env, eps):\n",
    "    history = []\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        action = choose_action_eps_greedy(q, state, eps)\n",
    "        next_state, reward, done = env.step(action)\n",
    "        history.append((state, action, reward))\n",
    "        state = next_state\n",
    "    return history\n",
    "        \n",
    "def choose_action_eps_greedy(q, state, eps):\n",
    "    if np.random.rand() < eps:\n",
    "        return np.random.randint(9)\n",
    "    else:\n",
    "        return np.argmax(q[state,:])\n",
    "    \n",
    "def create_first_visit_entries(history):\n",
    "    first_visit = -np.ones(800)\n",
    "    for idx, entry in enumerate(history):\n",
    "        if first_visit[entry[0]] == -1:\n",
    "            first_visit[entry[0]] = idx\n",
    "    return first_visit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On-policy first visit MC control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_visit_on_policy_mc_control(n_episode):\n",
    "    q = np.zeros((800,9))\n",
    "    eps = 1\n",
    "    env = Racetrack()\n",
    "    for episode in range(n_episode):\n",
    "        if episode % 5000 == 0:\n",
    "            eps /= 2\n",
    "        history = create_history_mc_episode(q, env, eps)\n",
    "        print(len(history), eps)\n",
    "        q = update_q_function(q, history)\n",
    "        \n",
    "def update_q_function(q, history):\n",
    "    g = 0\n",
    "    first_visit = create_first_visit_entries(history)\n",
    "    for idx, entry in enumerate(history[::-1]):\n",
    "        converted_idx = len(history)-idx-1\n",
    "        g += entry[2]\n",
    "        if first_visit[entry[0]] == converted_idx:\n",
    "            q[entry[0], entry[1]] += 0.01 * (g - q[entry[0], entry[1]])\n",
    "    return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_visit_on_policy_mc_control(50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordinary Importance Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordinary_importance_sampling_mc_control(n_episode):\n",
    "    q = np.zeros((800,9))\n",
    "    eps = 0.01\n",
    "    env = Racetrack()\n",
    "    for episode in range(n_episode):\n",
    "        history = create_history_mc_episode(q, env, eps)\n",
    "        print(len(history))\n",
    "        q = update_q_function_ordinary_is(q, history, eps)\n",
    "        \n",
    "def update_q_function_ordinary_is(q, history, eps):\n",
    "    g = 0\n",
    "    q_old = q.copy()\n",
    "    first_visit = create_first_visit_entries(history)\n",
    "    ratio = 1\n",
    "    for idx, entry in enumerate(history[::-1]):\n",
    "        ratio *= compute_importance_sampling_ratio_factor(entry[0], entry[1], q_old, eps)\n",
    "        if ratio == 0:\n",
    "            print('Ratio is zero in step ', idx)\n",
    "            break\n",
    "        converted_idx = len(history)-idx-1\n",
    "        g += entry[2]\n",
    "        if first_visit[entry[0]] == converted_idx:\n",
    "            q[entry[0], entry[1]] += 0.1 * ratio * (g - q[entry[0], entry[1]])\n",
    "    return q\n",
    "            \n",
    "def compute_importance_sampling_ratio_factor(state, action, q, eps):\n",
    "    ratio = 0\n",
    "    if np.argmax(q[state,:]) == action:\n",
    "        # prob of choosing the greedy action given the eps-greedy policy\n",
    "        ratio = 1 / (1 - eps + eps/9)\n",
    "    return ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4484455\n",
      "Ratio is zero in step  0\n",
      "1253202\n",
      "Ratio is zero in step  0\n",
      "1434563\n",
      "Ratio is zero in step  0\n",
      "1591783\n",
      "Ratio is zero in step  0\n",
      "732342\n",
      "Ratio is zero in step  0\n",
      "2294400\n",
      "Ratio is zero in step  0\n",
      "82359\n",
      "Ratio is zero in step  0\n",
      "447104\n",
      "Ratio is zero in step  0\n",
      "945146\n",
      "Ratio is zero in step  0\n",
      "2929891\n",
      "Ratio is zero in step  0\n",
      "1863284\n",
      "Ratio is zero in step  0\n",
      "2210049\n",
      "Ratio is zero in step  0\n",
      "371058\n",
      "Ratio is zero in step  0\n",
      "531041\n",
      "Ratio is zero in step  0\n",
      "632431\n",
      "Ratio is zero in step  0\n",
      "843995\n",
      "Ratio is zero in step  0\n",
      "2509317\n",
      "Ratio is zero in step  0\n",
      "1269138\n",
      "Ratio is zero in step  0\n",
      "1628586\n",
      "Ratio is zero in step  1\n",
      "888338\n",
      "Ratio is zero in step  0\n",
      "161479\n",
      "Ratio is zero in step  1\n",
      "671224\n",
      "Ratio is zero in step  0\n",
      "2219878\n",
      "Ratio is zero in step  0\n",
      "190682\n",
      "Ratio is zero in step  0\n",
      "129423\n",
      "Ratio is zero in step  0\n",
      "3093660\n",
      "Ratio is zero in step  0\n",
      "3246885\n",
      "Ratio is zero in step  0\n",
      "1508954\n",
      "Ratio is zero in step  0\n",
      "1146522\n",
      "Ratio is zero in step  1\n",
      "673888\n",
      "Ratio is zero in step  0\n",
      "142460\n",
      "Ratio is zero in step  0\n",
      "2794252\n",
      "Ratio is zero in step  0\n",
      "2206655\n",
      "Ratio is zero in step  0\n",
      "1199090\n",
      "Ratio is zero in step  0\n",
      "893476\n",
      "Ratio is zero in step  0\n",
      "700731\n",
      "Ratio is zero in step  0\n",
      "1813434\n",
      "Ratio is zero in step  0\n",
      "708720\n",
      "Ratio is zero in step  0\n",
      "2615794\n",
      "Ratio is zero in step  0\n",
      "2622586\n",
      "Ratio is zero in step  0\n",
      "670075\n",
      "Ratio is zero in step  0\n",
      "2108403\n",
      "Ratio is zero in step  0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-732034e57295>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mordinary_importance_sampling_mc_control\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-4867f3fa8e25>\u001b[0m in \u001b[0;36mordinary_importance_sampling_mc_control\u001b[0;34m(n_episode)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRacetrack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepisode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_episode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_history_mc_episode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_q_function_ordinary_is\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-d19e33b66a61>\u001b[0m in \u001b[0;36mcreate_history_mc_episode\u001b[0;34m(q, env, eps)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchoose_action_eps_greedy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-d19e33b66a61>\u001b[0m in \u001b[0;36mchoose_action_eps_greedy\u001b[0;34m(q, state, eps)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_first_visit_entries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repos/rl-zoo/venv/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36margmax\u001b[0;34m(a, axis, out)\u001b[0m\n\u001b[1;32m    974\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 976\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    977\u001b[0m     \"\"\"\n\u001b[1;32m    978\u001b[0m     \u001b[0mReturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mindices\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmaximum\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0malong\u001b[0m \u001b[0man\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ordinary_importance_sampling_mc_control(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted Importance Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
